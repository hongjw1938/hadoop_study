##  3. 빅데이터 수집
>###    3.1 빅데이터 수집 개요
        * 빅데이터 수집
            - 빅데이터 프로젝트는 여러 공정 단계가 있지만, 수집이 절반 이상
            - 일반적 수집과 달리 수집 영역이 조잭 내의 전체 시스템 ~ 외부 시스템에 이름
        * 수집 기술
            - 매우 빠르게 발전 중.
            - 과거에는 맵리듀스 기반의 주기적 배치성 분석 수행이 주
            - 현재는 수집과 동시에 분석 수행 >> ESP(Event Stream Processing), CEP(Complex Event Processing)
        * 수집/적재, 분석 영역 도출 무엇이 우선?
            - 선수집/후분석의 경우 우선 수집/적재에 집중하여 불필요한 리소스 낭비 발생 가능
            - 장시간에 걸친 탐색적 분석이 진행되므로 단기간 내에 성과 달성 어려움
            - 타부서의 협조와 경영진의 의사결정 이루기 쉽지 않음
            ---------------------------
            - 선분석/후수집의 경우 단기간에 최소 비용으로 성과를 낼 수 있음
            - 실패 시 부정적 인식이 사업 초기에 생성됨.
            - 외부 파트너에 대한 기술적 의존도 높아지고 역량 내재화 어려움, 사업 확장 시 비용 증가
>###    3.2 빅데이터 수집에 활용되는 기술
        ** 플럼
            * 소개
                - 빅데이터 수집시 다양한 수집 요구사항들을 해결하기 위한 기능으로 구성된 소프트웨어
                - 특히 데이터를 원천으로부터 수집시 통신 프로토콜, 메시지 포맷, 발생 주기, 데이터 크기 등으로 많은 고민거리 생김
                - 플럼은 이러한 고민을 해결할 수 있는 기능과 아키텍쳐 제공
            * 플럼 기본요소
                >> Source
                    - 다양한 원천 시스템의 데이터 수집을 위해 여러 주요 컴포넌트 제공. 수집 데이터를 Channel로 전달
                >> Sink
                    - 수집한 데이터를 Channel로부터 전달받아 최종 목적지에 저장하기 위한 기능으로 HDFS, Hive, Logger, Avo 등을 제공
                >> Channel
                    - Source와 Sink를 연결하며, 데이터를 버퍼링하는 컴포넌트, 파일, 데이터베이스를 채널의 저장소로 활용
                >> Interceptor
                    - Source와 Channel사이에서 데이터 필터링 및 가공하는 컴포넌트, 필요 시 추가
                >> Agent
                    - Source -> (Interceptor) -> Channel -> Sink 컴포넌트 순으로 구성된 작업 단위, 독립된 인스턴스로 생성
            * 플럼 아키텍쳐
                - 매우 직관적.
                - Source에서 데이터 로드, Channel에서 임시 저장, Sink를 통해 목적지에 데이터 최종 적재
                - 다양한 방식의 아키텍쳐 사용. 교재 110, 111참고
            * 플럼 활용방안
                - 스마트카에서 발생하는 로그 직접 수집
                - 100대의 스마트카에 대한 상태 정보 로그 파일이 로그 시뮬레이터를 통해 매일 생성됨
                - 상태 정보 파일을 플럼 에이전트가 일 단위로 수집해 하둡에 적재, 향후 배치 분석에 활용
                - 스마트카 운전자 100명의 운행 정보를 실시간으로 기록하는 로그 파일이 로그 시뮬레이터에 의해 생성
                - 발생과 동시에 플럼 에이전트가 수집해 카프카에 전송
        ** 카프카
            * 소개
                - MOM(Message Oriented Middleware) 소프트웨어 중 하나로서 대규모로 발생하는 메시지성 데이터를 비동기 방식으로 중재하는 역할
                - 원천 시스템으로부터 대규모 트랜잭션 데이터 발생시 중간에 데이터를 버퍼링하면서 타깃 시스템에 안정적으로 전송해주는 중간 시스템
            * 기본요소
                >> Broker 
                    - 서비스 인스턴스. 다수의 Broker를 클러스터로 구성. Topic이 생성되는 물리적 서버
                >> Topic
                    - Broker에서 데이터의 발행/소비 처리를 위한 저장소
                >> Provider
                    - Broker의 특정 Topic에 데이터를 전송하는 역할. 카프카 라이브러리 이용해 구현
                >> Consumer
                    - Broker의 특정 Topic에서 데이터를 수신하는 역할. 카프카 라이브러리 이용해 구현
            * 아키텍쳐
                - 세 가지 아키텍처 구성 가능. 주키퍼 반드시 이용.
                1) 싱글 브로커/싱글 노드 : 1대의 카프카 서버. 1개의 Broker만 구성 업무 도메인이 단순시 사용
                2) 멀티 브로커/싱글 노드 : 1대의 카프카 서버, 2개의 Broker로써 메시지 처리 분리 관리시 이용
                3) 멀티 브로커/멀티 노드 : 2대 이사으이 카프카 서버로 멀티 브로커 생성, 대규모 발행/소비 데이터 처리에 적합
            * 활용방안
                - 플럼이 실시간 데이터를 수집해 카프카 토픽에 전송시 카프카는 전송받은 데이터를 토픽에 임시 저장.
                - 컨슈머 프로그램이 작동해 토픽에서 데이터 가져감
                - 목적은 플럼이 빠르게 발생하는 데이터를 실시간으로 수집시 이를 최종 목적지에 전달하기 전 중간에서 안정적 버퍼링 처리가 필요하기 때문
                - 스마트카 운전자의 운행 정보는 100명이 1초 간격으로 데이터 발생시키므로 매우 부담스러움
                - 카프카와 같은 분산 환경의 대규모 중간 저장소가 완충 역할
                - 만약 카프카 없이 HBase에 전달시, 장애가 발생하면 플럼으로도 장애가 이어짐. 데이터 유실 발생.
                - 카프카가 있으면, HBase에서 장애가 발생해도 데이터 저장해 놓아다가 HBase가 복구시 곧바로 재처리 가능
>###    3.3 수집 파일럿 실행 1단계 - 수집 아키텍쳐
>###    3.4 수집 파일럿 실행 2단계 - 수집 환경 구성
>###    3.5 수집 파일럿 실행 3단계 - 플럼 수집 기능 구현
>###    3.6 수집 파일럿 실행 4단계 - 카프카 수집 기능 구현
>###    3.7 수집 파일럿 실행 5단계 - 수집 기능 테스트