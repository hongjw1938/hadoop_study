##  5. 빅데이터 적재2 - 실시간 로그/분석 적재
>###    5.1 빅데이터 실시간 적재 개요
        * 실시간성 처리
            - 실시간 로그 분석에서는 적재 직전에 실시간 분석 작업을 수행해 그 결과를 인메모리 시스템에 전달하여 주변 응용 시스템과 빠르게 공유할 수 있어야 한다.
            - 실시간으로 발생하는 대규모 메시지성 데이터를 영구적으로 저장하기에 하둡은 효율이 떨어지므로 HBase 같은 NoSQL 데이터 베이스를 사용한다.
>###    5.2 빅데이터 실시간 적재에 활용되는 기술
        ** HBase
            * 소개
                - 하둡 기반의 칼럼 지향 NoSQL 데이터베이스
                - 데이터를 키/값 형식으로 단순하게 구조화하는 대신 고성능의 쓰기/읽기가 가능토록 만듬
                - HBase의 경우 특히 쓰기 성능에 최적화됨.
                - 대용량 처리가 필요한 대규모 NoSQL 아키텍처 구성이 필요시 자주 사용됨
            * 주요 구성 요소
                - HTable : 칼럼 기반 데이터 구조를 정의한 테이블. 공통점있는 칼럼들의 그룹을 묶은 칼럼 패밀리와 테이블의 로우를 식별해서 접근하기 위한 로우키로 구성
                - HMaster : HRegion 서버를 관리. HRegion들이 속한 HRegion 서버의 메타 정보를 관리
                - HRegion : HTable의 크기에 따라 자동으로 수평 분할 발생. 이 분할된 블록을 HRegion단위로 지정
                - HRegionServer : 분산 노드별 HRegionServer가 구성됨. 하나의 HRegionServer에는 다수의 HRegion이 생성되어 그것을 관리
                - Store : 하나의 Store에는 칼럼 패밀리가 저장 및 관리됨. MemStore와 HFile로 구성
                - MemStore : Store내의 데이터를 인메모리에 저장 및 관리하는 데이터 캐시 영역
                - HFile : Store내의 데이터를 스토리지에 저장 및 관리하는 영구 저장 영역
            * 아키텍처
                - 가장 큰 특징은 하둡의 HDFS를 기반으로 설치 및 구성된다는 것.
                - 클라이언트가 HBase에 테이블에 특정 데이터를 저장하기 전 주키퍼를 통해 HTable의 기본 정보와 해당 HRegion의 위치 정보를 알아냄
                - 해당 정보 기반으로 클라이언트가 직접 HRegionServer로 접속해서 HRegion의 Memory 영역인 MemStore에 데이터를 저장
                - 이 때, MemStore의 설정된 임계치 값에 따라 특정 시점이 되면 MemStore에 있던 데이터가 HFile로 플러시되고, HFile 역시 약속된 임계치의 이벤트 시점이 되면 하둡의 HDFS로 데이터를 플러시함.
                - 이 플러시 과정이 Major/Minor Compaction이라고 불림.
            * 활용방안
                - 앞서 스마트카 운전자의 운행 정보를 카프카까지 전송했음.
                - 이번에는 카프카에 저장된 데이터를 스톰이 받아서 HBase의 테이블에 모두 적재함
                - HBase에 저장된 운잔자의 운행 정보를 특정 조건에 따라 필터링하여 신속히 조회해 보고, 하이브 핸들러를 이용해 HBase에 저장된 데이터를 다양히 활용
        ** 레디스
            * 소개
                - 분산 캐시 시스템. NoSQL 데이터 베이스처럼 대규모 데이터 관리 능력도 갖툰 IMDB(In-Memory Data Grid) 소프트웨어
                - 키/값 형식의 데이터 구조를 분산 서버상의 메모리에 저장하면서 고성능의 응답 속도 보장
                - 다양한 데이터 타입을 지원하기에 데이터 구조화해서 저장 가능. 
                - 인메모리 데이터를 영구적으로 저장 가능한 스냅샷 기능 제공
                - 데이터 유실에 대비해 AOF(Append Only File)기능으로 정합성 보장
                - 데이터의 샤딩과 복제도 지원하여 높은 성능이 필요한 서비스에서 많이 사용됨.
            * 주요 구성 요소
                - Master : 분산 노드 간의 데이터 복제와 Slave 서버의 관리를 위한 마스터 서버
                - Slave : 다수의 Slave 서버는 주로 읽기 요청을 처리. Master 서버는 쓰기 요청을 처리
                - Sentinel : 레디스 3.x에서 지원하는 기능. Master서버에 문제 발생시 새로운 Master서버 선출
                - Replication : Master서버에 쓰인 내용을 Slave서버로 복제해 동기화 처리
                - AOF/Snapshot : 데이터를 영구적으로 저장하는 기능. 명령어 기록의 AOF와 스냅샷 이미지 파일 형식 지원
            * 아키텍쳐
                - 교재 참조
            * 활용방안
                - 스마트카 운전자의 상태 정보를 실시간 분석하고 결과를 빠르게 저장하며 주변 시스템과 공유하기 위한 저장소로써 활용
        ** 스톰
            * 소개
                - 빅데이터 프로젝트에서 실시간 데이터를 병렬 프로세스로 처리하기 위한 소프트웨어
                - 스피드 데이터라는 용어 등장. 그것은 원천 시스템으로부터 데이터가 끊이지 않고 매우빠르게 유입됨.
                - 이 대규모 데이터를 병렬 처리를 이용해 실시간 데이터를 프로세싱 할 수 있는 소프트웨어가 필요해짐. 그것이 실시간 분산 처리기 스톰
            * 주요 구성 요소
                - Spout : 외부로부터 데이터를 유입받아 가공 처리해서 튜플 생성. 이후 해당 튜플을 Bolt에 전송
                - Bolt : 튜플을 받아 실제 분산 작업 수행. 필터링, 집계, 조인등의 연산 병렬 실행
                - Topology : Spout-Bolt의 데이터 처리 흐름을 정의. 하나의 Spout과 다수의 Bolt로 구성
                - Nimbus : Topology를 Supervisor에 배포하고 작업 할당. Supervisor를 모니터링하다 필요 시 페일오버 처리
                - Supervisor : Topology를 실행할 Worker를 구동. Topology를 Worker에 할당 및 관리
                - Worker : Supervisor 상에서 실행 중인 자바 프로세스로 Spout와 Bolt를 실행
                - Executor : Worker내에서 실행되는 자바 스레드
                - Tasker : Spout및 Bolt 객체가 할당
            * 아키텍쳐
                - 교재 참조
            * 활용방안
                - 실시간 운행 정보를 대상으로 데이터 라우팅과 스트리밍 처리에 활용
                - 카프카의 Spout을 통해 유입되는 모든 운전자의 운행 정보 데이터는 두 개의 Bolt로 나눠져 처리되는데,
                - HBase Bolt는 모든 운행 정보를 정제 없이 그대로 적제하며, 레디스 Bolt는 에스퍼의 룰 엔진이 감지한 이벤트 데이터로 이상 패턴의 운행 정보만 적재하게 됨.
        ** 에스퍼
            * 소개
                - 실시간 스트리밍 데이터의 복잡한 이벤트 처리가 필요할 때 사용하는 룰 엔진
                - 스톰은 대규모의 실시간 데이터를 단순 가공 및 추출 처리하는 데는 문제가 없으나, 실시간으로 발생하는 데이터로부터 복잡한 패턴을 찾고, 그 패턴에 따른 이벤트를 처리하는 기능은 부족
                - 실시간으로 발생하는 데이터 간의 관계를 복합적으로 판단 및 처리하는 것을 CEP(Complex Event Processing)이라고 하는데, 에스퍼가 바로 CEP 엔진 중 하나임
            * 주요 구성 요소
                - Event : 실시간 스트림으로 발생하는 데이터들의 특정 흐름 또는 패턴을 정의
                - EPL : 유사 SQL을 기반으로 하는 이벤트 데이터 처리 스크립트 언어
                - Input Adapter : 소스로부터 전송되는 데이터를 처리하기 위한 어댑터 제공
                - Output Adapter : 타깃으로 전송하는 데이터를 처리하기 위한 어댑터 제공
                - Window : 실시간 스트림 데이터로부터 특정 시간 또는 개수를 설정한 이벤트들을 메모리 상에 등록한 후 EPL을 통해 결과 추출
            * 아키텍쳐
                - 교재참조
            * 활용 방안
                - 운전자의 운행 데이터를 실시간으로 분석하기 위해 에스퍼 EPL을 활용
                - EPL은 30초 동안의 평균 시속을 체크해서 80km/h를 초과하는 운전자 이벤트 정보를 실시간으로 감지할 수 있도록 룰을 정의
                - 해당 이벤트 데이터는 감지 즉시 레디스에 적재되어 과속한 차량 정보만 관리할 수 있게 됨.
